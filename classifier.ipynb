{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U scikit-learn\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "test_dir = 'test_images'\n",
    "classes = ['Bulging Eyes', 'Cataracts', 'Crossed Eyes', 'Glaucoma', 'Healthy Eyes', 'Uveitits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(test_dir):\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')\n",
    "#tests = tf.keras.utils.image_dataset_from_directory('test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get another batch from the iterator \n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images Represented as numpy arrays\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 1 = Sad \n",
    "# Class 0 = happy\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 5, figsize =(20,20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = batch[0] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x / 255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 5, figsize =(20,20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "val_size = int(len(data) * .2)\n",
    "test_size = int(len(data) * .1) + 2\n",
    "\n",
    "train_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 2, padding = 'same', activation = 'relu', input_shape = (256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(Conv2D(64, (3,3), 2, padding = 'same', activation = 'relu', ))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(Conv2D(128, (3,3), 2, padding = 'same', activation = 'relu', ))\n",
    "model.add(Conv2D(128, (3,3), 2, padding = 'same', activation = 'relu', ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(6, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile('adam', loss = tf.losses.sparse_categorical_crossentropy, metrics =['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
    "hist = model.fit(train, epochs = 100, validation_data = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'teal', label = 'loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'orange', label = 'val_loss')\n",
    "fig.suptitle('Loss', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'teal', label = 'accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color = 'orange', label = 'val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can test the NN here by passing in an image\n",
    "img = cv2.imread('/Users/jbullock/EyeCU/test_images/cataracttest.jpg')\n",
    "#/Users/jbullock/EyeCU/test_images/uveitistest2.jpg\n",
    "#C:/Users/Ethan/OneDrive/Documents/GitHub/EyeCU/test_images/uveitistest2.jpg\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to resize the image before we pass it into the NN\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "img_array = tf.keras.utils.img_to_array(resize)\n",
    "img_array = tf.expand_dims(resize, 0) # Create a batch\n",
    "\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = np.round(model.predict(batch[0]), 1)\n",
    "#r = np.round(preds,5).argmax()\n",
    "#r\n",
    "preds\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if preds[i][j] == 1:\n",
    "            print('This image belongs to: ' + classes[j])\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(preds,6).argmax()\n",
    "\n",
    "\n",
    "print(preds[0])\n",
    "\n",
    "pred_labels = []\n",
    "\n",
    "for i in range(6):\n",
    "    r = np.round(preds[i],0).argmax()\n",
    "    print(r)\n",
    "    if r ==0 : pred_labels.append(\"Bulging Eyes\")\n",
    "    elif r ==1: pred_labels.append(\"Cataracts\")\n",
    "    elif r ==2: pred_labels.append(\"Crossed Eyes\")\n",
    "    elif r ==3: pred_labels.append(\"Glaucoma\")\n",
    "    elif r ==4: pred_labels.append(\"Healthy Eyes\")\n",
    "    elif r ==5: pred_labels.append(\"Uveitis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = batch[0][:6]\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for m in range(1, 7):\n",
    "    img = images[m-1].reshape([256, 256, 3])\n",
    "    fig.add_subplot(5, 5, m)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Pred: \" + pred_labels[m-1])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_array = tf.keras.utils.img_to_array(resize)\n",
    "img_array = tf.expand_dims(resize, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(classes[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "np.argmax(score)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(img):\n",
    "  img_array2 = tf.keras.utils.img_to_array(img)\n",
    "  img_array2 = tf.expand_dims(img, 0)\n",
    "  prediction = np.round(model.predict(img_array2))\n",
    "  for i in range(6):\n",
    "    for j in range(6):\n",
    "      if prediction[i][j] == 1:\n",
    "        return classes[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(256,256))\n",
    "label = gr.outputs.Label(num_top_classes=6)\n",
    "\n",
    "#interface = gr.Interface.load(\"huggingface/jazmineox/Eye_classification\", fn=predict_image, inputs=image, outputs=label,interpretation='default')\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True', share=True)\n",
    "\n",
    "#interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
